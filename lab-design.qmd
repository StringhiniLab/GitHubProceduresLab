# What is the lab's policy for data and code usage? {.unnumbered}  

## Statement of Need

[Dr. Silvia Stringhini](https://spph.ubc.ca/faculty/associate-professors/silvia-stringhini/) is an epidemiologist with an extensive career. She has served as the Head of the Unit of Population Epidemiology at the Geneva University Hospitals and as an Assistant Professor at the University of Geneva, Switzerland. Her main research areas include social inequalities in chronic diseases and aging, the role of health behaviors in the genesis of social health inequalities, the biological consequences of social inequalities, and the role of environmental factors in social health disparities. 

Recently, she moved her lab to the [School of Population and Public Health](https://spph.ubc.ca/) at the [University of British Columbia](https://www.ubc.ca/) in Canada, where she is establishing a new team. Currently, she is in the process of welcoming new students and staff, making this an ideal time to outline how her new group will manage data and code in its publications.  

We discussed with Dr. Stringhini the minimum data management requirements for joining the group. We reached a consensus on the following points:


| Objective | What does the manual cover? |  
| --------- | ------------------------- |  
| Centralize copies of data analyses from all lab members | Create a GitHub organization |  
| Creation of public repositories for articles and private ones for preliminary data analyses | - Guidelines for creating public repositories for scientific article analyses </br> - Guidelines for creating private repositories |  
| Sensitive data | - `.gitignore` </br> - Project structure including how to organize the data folder |  
| Onboarding | - Create a GitHub account </br> - Install software |  

## Why Use GitHub?

Git and GitHub were originally created for professional software development. However, their use has extended into the scientific field for various reasons:

- **Backup**  
Making it a habit to push to GitHub at least once a day allows you to keep an online copy of your data analysis.

- **Improved Documentation Practices**  
Having a complete README and knowing that your colleagues have access to your code encourages better organization of the project, making it clearer, more concise, and well-documented.

- **Version Control**  
It is easy to see how the project has evolved over time and recover changes from previous versions.

- **Reproducibility**  
When publishing scientific articles, maintaining reproducible results is considered a quality practice.  

Itâ€™s important to clarify that lab members are not expected to be expert users of Git and GitHub, but rather to handle basic commands necessary to achieve the use proposed.

## Notes on Instructional Design

We recognize that creating the code for a scientific publication takes time and involves numerous attempts before deciding what figures and results effectively will be published. Keeping this in mind, it was decided that each student would generate a **private GitHub repository** by project to maintain a backup of daily data analyses conducted in the lab. This private repository could then serve as the foundation for a public version for the final GitHub repository with the scientific article's code. Also, publicly exposing the behind-the-scenes details of data management and analysis can be more challenging for early-career researchers, who can fear of public scrutiny of code (@gomes2022, @tazare2024). 

Maintaining this initial private repository has other benefits besides functioning as a backup: it allows sharing the code with other lab members (as part of a GitHub lab team), makes available analyses that may not be included in the final paper but could be relevant for another publication, helps keeping a clearer project structure from the beginning and **improves the overall documentation of the project**.  

Specific characteristics of the research area were also discussed (@maya2023), such as handling **sensitive data** (@turing). As a result, practices like using `.gitignore` and setting up a structured data folder with `raw` and `processed` sub folders were suggested to prevent private data from being pushed to GitHub and to maintain an orderly system for storing such information within the project. Also, we created a friendly for non programmers README template, to be sure that the relevant information, as the database version in use and computational environment, is captured.  

One of the more challenging aspects to adopt is using Git, as it has multiple utilities and a considerable learning curve. Considering this, it was decided that, in this initial stage, Git and GitHub's primary use would be to create an online and centralized backup of the projects, share repositories among team members, and manage version control instead of focusing in collaborative tools.

Since R is the most widely used programming language in the discipline, the team decided to leverage the Git integration provided by RStudio IDE's Git tab for committing changes and integrating students' local work into the GitHub repositories.  

## Future steps

## Summary

Most of the databases used in our lab are private and do not contain enough data to be considered big data. These databases are used locally. 

- It is suggested to use a `raw/` folder and a `processed/` folder to separate unprocessed data from processed data.
- To ensure that the data is not made public, it is recommended to use a `.gitignore` file and avoid pushing the folder where the data is stored to the repository.
- Provide a quick onboarding guide and basic data management practices for new lab members, including data analysis backup and how to maintain the privacy of datasets by having clear steps to prevent pushing data.  
- Set guidelines on the use and management of code within the lab to facilitate sharing unpublished or complementary data analysis among current and former lab members.  
- Establish basic rules to publish public repositories associated with scientific articles, ensuring transparency in analyses and reproducibility of results.  
- Ensure consistency in managing data analyses over time and preserve and centralize the knowledge generated in the different projects.  

## References


